{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12adacc-007f-40fb-a86e-37ec50ac2b6f",
   "metadata": {},
   "source": [
    "# Distributed Computation\n",
    "\n",
    "## Quick Recap - Multiprocessing vs. Multithreading\n",
    "\n",
    "Multiprocessing can utilize multiple CPU cores, thus achieving a more authentic sense of parallel computation. However, multiprocessing suffers when they need to share a common memory space.\n",
    "\n",
    "On the other hand, multithreading can share a common memory space and achieve a more loose sense of parallel computation. As a result, multithreading is more like hyper-jumping through multiple queues (within the same process) while waiting for each particular thread's turn:\n",
    "\n",
    "1. When it is one specific thread's turn, it will acquire the Global Interpreter Lock (GIL) to control the memory space _and_ the CPU core until it finishes its designated computation or hits another \"busy-waiting\" block (such as I/O actions).\n",
    "2. Then, the loop releases the GIL and lets the jump proceed (context-switch) to the following thread.\n",
    "3. Rinse and repeat (until done).\n",
    "\n",
    "You can revisit [part 13](../13-data-processing.ipynb) for more details on this subject.\n",
    "\n",
    "### Asynchronous I/O Loops, and Multithreading's Little Brother - Coroutines\n",
    "\n",
    "Both multiprocessing and multithreading require dedicated hardware or operating system support. As software technologies mature, engineers started to explore capabilities within the application layer itself. As a result, the same conceptual model of multithreading gets a new interpretation within the programming stack (such as Python), giving more direct control to the program within the runtime instead of relying on the OS mechanism to switch context. The term [_Coroutine_](https://en.wikipedia.org/wiki/Coroutine), first coined in 1958, is a materialization of the concept of lightweight threads.\n",
    "\n",
    "Both multithreading and coroutine techniques are suitable for I/O focused tasks, such as reading files from a disk or making HTTP requests. However, coroutines tend to require less computing resource overhead than threads by giving up some performance benefit from tapping into the more OS-native mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e3a796-c985-4659-a933-2d4dde6a1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "\n",
    "\n",
    "# 5 requests, each with delays ranging from 1-3 seconds\n",
    "reqs = [\n",
    "    f'https://httpbin.org/delay/{random.randint(1, 3)}'\n",
    "    for _ in range(5)\n",
    "]\n",
    "\n",
    "def get_sync():\n",
    "    all_data = []\n",
    "    for req in reqs:\n",
    "        res = requests.get(req)\n",
    "        all_data.append(res.json())\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8483a5c-e857-41d8-8191-14e5ff96132a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.2 ms, sys: 10.3 ms, total: 94.5 ms\n",
      "Wall time: 10.5 s\n",
      "{'args': {}, 'data': '', 'files': {}, 'form': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.25.1', 'X-Amzn-Trace-Id': 'Root=1-60d65367-3503a36e56f6d53f2ca31a75'}, 'origin': '107.179.188.69', 'url': 'https://httpbin.org/delay/1'} 5\n"
     ]
    }
   ],
   "source": [
    "%time res = get_sync()\n",
    "print(res[-1], len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107f433-9bc4-4b0f-9dd1-77603dfaa07a",
   "metadata": {},
   "source": [
    "In Python, [the `asyncio` module](https://docs.python.org/3/library/asyncio.html) provides a standard set of APIs for its users to utilize coroutines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b010385-d4ff-4870-9e0e-4f1164dc465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "async def get(session, url):\n",
    "    res = await session.request('GET', url=url)\n",
    "    data = await res.json()\n",
    "    return data\n",
    "\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for req in reqs:\n",
    "            tasks.append(get(session, url=req))\n",
    "\n",
    "        all_data = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7ffa8-f260-4c4e-ae5f-ac3d4c6eb658",
   "metadata": {},
   "source": [
    "There are two caveats about utilizing `asyncio` in the Jupyter Notebook environment:\n",
    "1. We cannot use the %time magic command for async functions.\n",
    "2. We cannot initiate an explicit event loop (it's already in one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f338e2f-1951-4558-bf6d-531bd7becb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 seconds\n",
      "{'args': {}, 'data': '', 'files': {}, 'form': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Host': 'httpbin.org', 'User-Agent': 'Python/3.8 aiohttp/3.7.4.post0', 'X-Amzn-Trace-Id': 'Root=1-60d65368-2ca9bf10688e9d1638a9e1bb'}, 'origin': '107.179.188.69', 'url': 'https://httpbin.org/delay/1'} 5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# loop = asyncio.get_event_loop()\n",
    "# loop.run_until_complete(main())\n",
    "start = time.time()\n",
    "res = await main()\n",
    "print(round(time.time() - start, 1), 'seconds')\n",
    "print(res[-1], len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866076f-3616-4e9b-8b48-2c07c6f5f627",
   "metadata": {},
   "source": [
    "Let's use the responses to verify what the delays were in the API calls by using functional techniques `map()` and `reduce()` to extract delays (in seconds) and sum them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920e2588-47d2-44a4-a979-2f14739fe203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 1, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delay_mapper(url):\n",
    "    return int(url.split('/')[-1])\n",
    "\n",
    "delays = list(map(delay_mapper, reqs))\n",
    "delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658e2b6b-5d19-44eb-a486-b6841d3bf1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def delay_reducer(left, right):\n",
    "    return left + right\n",
    "\n",
    "# same as calling `sum(delays)`\n",
    "total_delay = reduce(delay_reducer, delays, 0)\n",
    "total_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be12faf4-d0ea-4921-b5e1-01a864f7aa8b",
   "metadata": {},
   "source": [
    "The total theoretical delay matches our observation from the synchronous process, while the _maximum_ from individual delays matches what we saw from the asynchronous version.\n",
    "\n",
    "## MapReduce - Distributing Computing Resources\n",
    "\n",
    "Recall one of the most critical disadvantages of multiprocessing - the lack of shared memory space. One workaround of such an issue is to leverage the filesystem as an inter-process data pool so that multiple processes can simultaneously read and write to it, such as a local SQLite database, as demonstrated in [part 11](../11-work-with-sql.ipynb).\n",
    "\n",
    "Suppose we extend this problem to a larger scale, where the dataset we want to work with exceeds the available memory space and is impossible to efficiently store (or at all) on the disk of a single machine. In that case, we need to revisit viable solutions.\n",
    "\n",
    "The MapReduce model is a _divide and conquer_ strategy applying and extending the functional programming concepts of `map()` and `reduce()`. Through this model, a large dataset is dissected and distributed through a mapping procedure onto a multitude of computational nodes to parallelize the computation of the smaller portion, then reducing the resulting subsets back to fewer nodes until the cluster concludes the outcome.\n",
    "\n",
    "A simple demonstration of how the MapReduce model helps with tallying the number of occurrences of unique words of a given paragraph:\n",
    "\n",
    "![MapReduceImage](https://user-images.githubusercontent.com/58446818/123367276-adc9a600-d547-11eb-9a37-5b91ce2eb090.png)\n",
    "\n",
    "This model allows batch data processing to have a near-infinite capacity and a relatively cost-effective way to speed up the process.\n",
    "\n",
    "It is worth noting that the development of cheaper and faster hard drives, especially the more widespread adoption of SSDs (solid-state drive), plays a vital role in enabling distributed computation.\n",
    "\n",
    "The MapReduce model was first pioneered [by Google](https://research.google/pubs/pub62/) in 2004 to resolve the practical problem of exponentially growing datasets for computing their search indexes. Then many have adopted and contributed toward the technology's development and evolution through the open-source community.\n",
    "\n",
    "### Apache Sparkâ„¢\n",
    "\n",
    "Apache Spark is such an open-source framework that came around 2014 that provides an elegant and unified abstraction on top of proven technologies such as SQL to enable large-scale data processing that can efficiently utilize from a single machine to \"multiple clouds.\" You can find more comprehensive examples in [Spark's DataFrame usage notebook](./spark-dataframe-usage.ipynb).\n",
    "\n",
    "For the sake of simplicity, we will demonstrate its distributed nature on multiple cores of a single machine. First, obtain the number of CPU core:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d2d71cc-fdac-4c6e-985f-8a7f784b37a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "CORES = multiprocessing.cpu_count()\n",
    "CORES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ec5e4-c646-4357-b372-78c5d1d4e8e7",
   "metadata": {},
   "source": [
    "Borrowing from [part 12](../12-generate-data.ipynb), where we attempted to generate random and hashed device IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab89d25-26a1-4bf9-841b-23005c22b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly from Part 12 - Generate data\n",
    "from uuid import uuid4\n",
    "from hashlib import sha1\n",
    "\n",
    "\n",
    "def gen_device_ids(count: int = 20_000) -> list:\n",
    "    device_ids = []\n",
    "    for _ in range(count):\n",
    "        device_ids.append(str(uuid4()))\n",
    "    # hash\n",
    "    return [sha1(x.encode()).hexdigest() for x in device_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5ea06-9dba-44f2-a653-9c2856366b4d",
   "metadata": {},
   "source": [
    "Let's generate a relatively large batch of device IDs, say 1 million times the number of `CORES`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7c6a45-9867-4cff-9f28-c58b3025ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.6 s, sys: 5.12 s, total: 56.7 s\n",
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%time device_ids = gen_device_ids(count=1_000_000 * CORES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8c3ce-3642-46b8-800b-418b0c753344",
   "metadata": {},
   "source": [
    "Due to the single iterative process, the time it takes is quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a5abe5-5615-46c8-947d-e04def2c91cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Âµs, sys: 0 ns, total: 2 Âµs\n",
      "Wall time: 4.05 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['7cd2e83fb6522438401ce0660ea33df317643282',\n",
       " 'dc0a36109d57c76f18ef47ff1f03ed84adcf7c37',\n",
       " 'c98398a8467c710fec4f568fa89052dd73f8e251',\n",
       " '6683b63b4e74d5086ea43277427c2c4e5895f3a1',\n",
       " '2be582b3bc39baa328314b262a4c0b235c6cbd31',\n",
       " '7588c798e2adf327ebf0ebed38258ae31c014797',\n",
       " 'beff860ca260e4a672357ca82d88f494c4215d82',\n",
       " 'e6bbd6fd9e896dfe67f5feb7894b12d01158d086',\n",
       " 'c9fb0404b1b233327535b9e9af5a1b66fb288d8b',\n",
       " '07d56f7665a4d4ffd25a4d270d844a65be63f8ae']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time device_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f65615-fedf-40cf-a8d7-f589c60f64be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Âµs, sys: 0 ns, total: 2 Âµs\n",
      "Wall time: 4.77 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time len(device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d143467-c776-4a3e-88d5-7ce64abebf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.40396881103516"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get size of the list in memory\n",
    "import sys\n",
    "\n",
    "sys.getsizeof(device_ids) / 1024 / 1024  # (bytes / 1024 = kilobytes) / 1024 = megabytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481733f-e3f3-4678-a2d9-7af6a53e8b54",
   "metadata": {},
   "source": [
    "But since the list is already in memory, it takes very little time to read them out.\n",
    "\n",
    "Let's try the same device ID generation with Spark in a distributed manner. We will initiate a Spark session with a local \"master\" that takes advantage of the number of `CORES` we have obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30282e77-5efc-45fb-8753-e1a006c4051c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://runzhoudembp.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[12]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1170f0700>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(f'local[{CORES}]').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d1fb0-1a29-45a8-a632-945ed4a6623a",
   "metadata": {},
   "source": [
    "The Spark UI, which runs on the `localhost`, is handy for monitoring and more.\n",
    "\n",
    "![Spark UI](https://user-images.githubusercontent.com/2837532/122995953-46a9c700-d378-11eb-84a7-50917d34b7be.png)\n",
    "\n",
    "The first approach involves a core concept and building block of Spark, known as Resilient Distributed Datasets (`RDD`s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb80f2ce-34df-4ab1-b043-4e6585ada283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.28 ms, sys: 1.92 ms, total: 4.2 ms\n",
      "Wall time: 211 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def mapper(count):\n",
    "    return [(d,) for d in gen_device_ids(count)]\n",
    "\n",
    "# a list of [1_000_000, ..., 1_000_000], where the length is the number of CORES\n",
    "counts = [1_000_000] * CORES\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(counts).flatMap(mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e05c8-c9ee-46e5-8301-0f3dbe2c15b5",
   "metadata": {},
   "source": [
    "The action takes a context from the available Spark session, scheduled to parallelize over a list of 1 million counts, where the list length is the number of `CORES`. Then we instruct the parallelization to map the Python list over a `mapper` function that takes the individual count and generates a list of device IDs (single element tuples). The `.flatMap` method is a convenient layer to ensure the resulting dataset as a single-tier list of device IDs instead of a list of (number of `CORES`) lists.\n",
    "\n",
    "Notice the time it takes to schedule is negligible, as Spark takes a _lazy_ approach to preserve computing resources until the computation is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c465a28-f5b8-4f0a-ae24-a7cf7a3e7219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(rdd)  # in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0df7f70-b1ee-44fe-af21-89c21df0221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.81 ms, sys: 2.35 ms, total: 7.16 ms\n",
      "Wall time: 5.85 s\n",
      "[('e91f9dc25c999662f850099e376f9f32fef205be',), ('2e67b668cb133c986aaf17abd9f5de02364abbeb',), ('c4f854dd3e58bfe3c6b509fdddbac9ed4136b55e',), ('9c3cf2cb226493cc7765de7cf2ec8568c5b55aa5',), ('d0a8f37d2a5bfe2009ea78ff6bd1980670f70316',), ('45eb2d467a1fc60ae2952ffa04d8f0a62dcf4585',), ('23483d77ae73f81d9146dab2bdc48a1e5b1c53d7',), ('66d3e32addcb2947fe4e143e04b8e45c1a52c2bb',), ('d6bac44706bc878615035418c8bbd664f33a0ead',), ('3a6ce532ac5a07ddcd6dd659eab8492c501936a8',)]\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "%time sample = rdd.take(10)\n",
    "print(sample)\n",
    "print(sys.getsizeof(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22793df6-78be-48e4-8b5c-87964f7230fc",
   "metadata": {},
   "source": [
    "Indeed, when we instruct to take the first ten values from the RDD, Spark would start the computation (and more). If we go back to the Spark UI, it may better picture what Spark has done under the hood.\n",
    "\n",
    "![RDD take](https://user-images.githubusercontent.com/2837532/122997519-16fbbe80-d37a-11eb-8704-5c520019e161.png)\n",
    "\n",
    "Conceptually, the workflow is as the following:\n",
    "1. Generate the device IDs leveraging multiple `CORES` in parallel.\n",
    "2. Persist device IDs as RDD into distributed blocks on disk. They have also replicated automatically across available distributions to support further parallelized processes. Spark also records other necessary metadata, such as the order of values, to ensure that computations that require strict ordering do not get affected.\n",
    "3. Draw the first ten values from the RDD files and populates them into the Python process that runs this Notebook.\n",
    "\n",
    "This workflow means that while it is significantly faster to generate the device IDs than the single process iterative approach, it is much slower to read. It involves a more complex trip to read from files while ensuring the order of values is intact.\n",
    "\n",
    "`RDD`s can be cached into memory (the part that has been computed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cedb132-2bc6-443f-a261-b75ffc8b3179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 ms, sys: 1.48 ms, total: 4.04 ms\n",
      "Wall time: 8.7 ms\n"
     ]
    }
   ],
   "source": [
    "%time rdd = rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a2c8a4-686e-42a1-b52c-241eff3f4f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.71 ms, sys: 2.68 ms, total: 8.38 ms\n",
      "Wall time: 5.17 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('c9324dbf49f601913389f91298819376c640252b',),\n",
       " ('54893f6f30c9fb488aa6ff0bc2cfef88eefbabdc',),\n",
       " ('0e089056983e9b613182614d781786fdca0c9383',),\n",
       " ('6b1064d8b83b14cfde476acc293abdf3cd9f8a1f',),\n",
       " ('4c71081fd137a66e7be0c5a49d8b9067250567c6',),\n",
       " ('12bcc13563bd78d09a40f352bd6761d130ba443a',),\n",
       " ('e26aa395866411e483d1b971f3df3a768e98a34a',),\n",
       " ('d1563b12f1e3959846ce4ebe9496700c88015794',),\n",
       " ('f84674ef8052bc69f82bba08e43e1c9e32053b6a',),\n",
       " ('044211b9d766b576e41dbb0417452e1a5f9598ef',)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rdd.take(10)  # first call to heat-up the cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ef033-5f26-493b-93e0-a05d53a21f10",
   "metadata": {},
   "source": [
    "Because it's cached, the consecutive call would be much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21fcfe69-6f6b-4cd7-ad88-193ee7688254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 ms, sys: 1.76 ms, total: 4.53 ms\n",
      "Wall time: 58.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('c9324dbf49f601913389f91298819376c640252b',),\n",
       " ('54893f6f30c9fb488aa6ff0bc2cfef88eefbabdc',),\n",
       " ('0e089056983e9b613182614d781786fdca0c9383',),\n",
       " ('6b1064d8b83b14cfde476acc293abdf3cd9f8a1f',),\n",
       " ('4c71081fd137a66e7be0c5a49d8b9067250567c6',),\n",
       " ('12bcc13563bd78d09a40f352bd6761d130ba443a',),\n",
       " ('e26aa395866411e483d1b971f3df3a768e98a34a',),\n",
       " ('d1563b12f1e3959846ce4ebe9496700c88015794',),\n",
       " ('f84674ef8052bc69f82bba08e43e1c9e32053b6a',),\n",
       " ('044211b9d766b576e41dbb0417452e1a5f9598ef',)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rdd.take(10)  # hitting on \"hot\" cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eac8f8-acc2-48f9-8c6c-2e2077667646",
   "metadata": {},
   "source": [
    "The following illustration shows the workflow of RDD operations:\n",
    "\n",
    "![RDD workflow](https://user-images.githubusercontent.com/2837532/123459338-28c8a600-d5b4-11eb-8ac8-c13c22456d5f.png)\n",
    "\n",
    "The Spark DataFrame builds on top of RDDs (and other filesystem abstractions or \"Data Lakes\"):\n",
    "\n",
    "![spark dataframe](https://user-images.githubusercontent.com/2837532/123487976-0008d680-d5dd-11eb-8abd-076bd3f9420f.png)\n",
    "\n",
    "The PySpark API offers a convenient pathway to get the DataFrame instance from existing RDDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79918937-4a6b-43ee-a35a-ad09406581d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 170 ms, sys: 48 ms, total: 218 ms\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%time df = rdd.toDF(['device_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80978d82-77ca-4c72-a07e-3d107e6208c3",
   "metadata": {},
   "source": [
    "Let's build an equivalent Pandas DataFrame from the same source `device_ids`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "668cfff9-de2a-41b4-a72d-fa13cc48d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14282bfc-a1f2-41a7-8e23-95a6e81a0804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 538 ms, sys: 182 ms, total: 719 ms\n",
      "Wall time: 719 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7cd2e83fb6522438401ce0660ea33df317643282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc0a36109d57c76f18ef47ff1f03ed84adcf7c37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c98398a8467c710fec4f568fa89052dd73f8e251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6683b63b4e74d5086ea43277427c2c4e5895f3a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2be582b3bc39baa328314b262a4c0b235c6cbd31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999995</th>\n",
       "      <td>ec11eff98662f443f429a6c9806bba653297735c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999996</th>\n",
       "      <td>1e8ff6732fbeeedb692884c86f64241f83f0b61e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999997</th>\n",
       "      <td>547848b7217f199f450e4fae2b6a5bd20a48be91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999998</th>\n",
       "      <td>07297e859807ed45651822fe31b7bbc48547fc5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999999</th>\n",
       "      <td>b5dca6dce3421cb06e45282404b33d89e6648f1c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         device_id\n",
       "0         7cd2e83fb6522438401ce0660ea33df317643282\n",
       "1         dc0a36109d57c76f18ef47ff1f03ed84adcf7c37\n",
       "2         c98398a8467c710fec4f568fa89052dd73f8e251\n",
       "3         6683b63b4e74d5086ea43277427c2c4e5895f3a1\n",
       "4         2be582b3bc39baa328314b262a4c0b235c6cbd31\n",
       "...                                            ...\n",
       "11999995  ec11eff98662f443f429a6c9806bba653297735c\n",
       "11999996  1e8ff6732fbeeedb692884c86f64241f83f0b61e\n",
       "11999997  547848b7217f199f450e4fae2b6a5bd20a48be91\n",
       "11999998  07297e859807ed45651822fe31b7bbc48547fc5b\n",
       "11999999  b5dca6dce3421cb06e45282404b33d89e6648f1c\n",
       "\n",
       "[12000000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pdf = pd.DataFrame(device_ids, columns=['device_id'])\n",
    "\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80250bd-5186-48cc-8fa1-d68d777000dc",
   "metadata": {},
   "source": [
    "Bearing the same understanding, the Spark DataFrame would be slower to read due to the round-trip it takes to the distributed disk blocks. But since the underlying `rdd` has been cached at this point, it can be pretty fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eb420e0-3da9-438a-ba00-769fd74c20bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           device_id|\n",
      "+--------------------+\n",
      "|c9324dbf49f601913...|\n",
      "|54893f6f30c9fb488...|\n",
      "|0e089056983e9b613...|\n",
      "|6b1064d8b83b14cfd...|\n",
      "|4c71081fd137a66e7...|\n",
      "|12bcc13563bd78d09...|\n",
      "|e26aa395866411e48...|\n",
      "|d1563b12f1e395984...|\n",
      "|f84674ef8052bc69f...|\n",
      "|044211b9d766b576e...|\n",
      "|6ebd9a4495cc47494...|\n",
      "|eaad7702e4acd033a...|\n",
      "|be7ffb95494caa17b...|\n",
      "|9de777eb0390b7992...|\n",
      "|be6e762732d2e1d47...|\n",
      "|6c9a749a94bb1891f...|\n",
      "|bd8e653d5cb07e0b2...|\n",
      "|3a8d4eed06ccb7f6c...|\n",
      "|7a68a5b2c4d777508...|\n",
      "|58cc17cc722346522...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 891 Âµs, sys: 1.01 ms, total: 1.9 ms\n",
      "Wall time: 667 ms\n"
     ]
    }
   ],
   "source": [
    "%time df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e93dcb6-db18-42ec-b2ba-b7773b3c00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 392 ms, sys: 6.95 ms, total: 399 ms\n",
      "Wall time: 397 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device_id    12000000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "418fede8-ede8-4edc-ad5d-db1c7e198864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 ms, sys: 848 Âµs, total: 2.42 ms\n",
      "Wall time: 17.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ede288-46d0-4cb0-8988-422d9d9f5e54",
   "metadata": {},
   "source": [
    "Spark would attempt optimization not to scan the full range of dataset when invoking partial readings such as `rdd.take()` or `df.show()`, but suffers a full-range scan when it needs to count the accurate number of items, hence the much longer duration.\n",
    "\n",
    "We can also build Spark DataFrames through the help of concatenating existing Pandas DataFrames. Much like how the Pandas DataFrame offers a set of convenient functions and methods to work with SQL, Spark (or, more accurately, PySpark) also provides easy access for Pandas DataFrames.\n",
    "\n",
    "Spark's backend is mainly implemented in [the Scala programming language](https://scala-lang.org/) and runs on the JVM (Java virtual machine) runtime. Its Python interface is enabled through a chain of clever abstractions and techniques to ensure that both the Python data structures and functions can execute effectively and efficiently.\n",
    "\n",
    "Below is an alternative approach for the device ID generation task by leveraging the robust support of Spark's native support to interface with Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bca3108-7df8-4744-adcb-26a2e221a769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.1 ms, sys: 6.85 ms, total: 52 ms\n",
      "Wall time: 250 ms\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(i,) for i in range(CORES)], ['cluster'])\n",
    "\n",
    "def _gen(df):\n",
    "    device_ids = gen_device_ids(count=1_000_000)\n",
    "    pdf = pd.DataFrame(device_ids, columns=['device_id'])\n",
    "    pdf['cluster'] = df['cluster']\n",
    "    return pdf.reset_index()\n",
    "\n",
    "def gen_device_ids_udf(df):\n",
    "    output = []\n",
    "    for _, row in df.iterrows():\n",
    "        pdf = _gen(df)\n",
    "        output.append(pdf)\n",
    "\n",
    "    return pd.concat(output)\n",
    "\n",
    "\n",
    "schema = 'index long, cluster long, device_id string'\n",
    "%time df = df.groupby('cluster').applyInPandas(gen_device_ids_udf, schema=schema).drop('cluster', 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe3c37-9cf6-439a-8b57-fac23ba580f5",
   "metadata": {},
   "source": [
    "A similar parallelization principle from the RDD approach applies here. Conceptually, there is a \"hack\" around the `.groupby()` mechanism, which enables the parallelization against the number of `CORES`.\n",
    "\n",
    "Like the RDD approach, the task scheduling does not take long, as we have yet to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d620162-9d26-46d5-871d-82b987b73541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           device_id|\n",
      "+--------------------+\n",
      "|68bf17b1d0af89122...|\n",
      "|b7b5a2d17323d64a3...|\n",
      "|f1aabf1dbe5432ef4...|\n",
      "|b52fd396ede302f65...|\n",
      "|03081dacf8c6ddc77...|\n",
      "|de2db80bb3ea5a92b...|\n",
      "|b0d119d46f9f51aed...|\n",
      "|37549cde277fc08cf...|\n",
      "|dc26d617527a4e868...|\n",
      "|85a7740583a88ffe4...|\n",
      "|95de6049660cacebf...|\n",
      "|f2074be5d9992f8e7...|\n",
      "|b744cf68a5e7289c4...|\n",
      "|7ce1e5872aa6e4a55...|\n",
      "|cff12672ddc5973ca...|\n",
      "|06630f4e2f5e7013c...|\n",
      "|3583e89bcc446572c...|\n",
      "|aebc986d1920d3cf7...|\n",
      "|e9a7c5d5941392ba9...|\n",
      "|e9c71536159874d03...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 3.33 ms, sys: 2.83 ms, total: 6.16 ms\n",
      "Wall time: 6.34 s\n"
     ]
    }
   ],
   "source": [
    "%time df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab32a57-cb9e-4c90-b769-0a5cdfd43f1d",
   "metadata": {},
   "source": [
    "Since this approach involves a more pronounced mapping process abstracted by the `.groupby` method, the underlying workflow can be a bit more interesting to observe:\n",
    "\n",
    "![group by](https://user-images.githubusercontent.com/2837532/123001100-5b895900-d37e-11eb-8b2a-db3fa40caaba.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5144c54a-b74a-43d4-94fc-953e27d84f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 ms, sys: 9.71 ms, total: 25.1 ms\n",
      "Wall time: 14.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908a266-8738-43b2-b96f-22cf114c11d8",
   "metadata": {},
   "source": [
    "Read access and the time consumption behaviours are within our expectations.\n",
    "\n",
    "Let's attempt to perform some actual analysis of the overall dataset, such as counting the number of device IDs by their first characters.\n",
    "\n",
    "We'll start with the Pandas DataFrame, which is in-memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d87e7dc-8cb7-4dfc-8810-993e34d40848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7cd2e83fb6522438401ce0660ea33df317643282</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc0a36109d57c76f18ef47ff1f03ed84adcf7c37</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c98398a8467c710fec4f568fa89052dd73f8e251</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6683b63b4e74d5086ea43277427c2c4e5895f3a1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2be582b3bc39baa328314b262a4c0b235c6cbd31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999995</th>\n",
       "      <td>ec11eff98662f443f429a6c9806bba653297735c</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999996</th>\n",
       "      <td>1e8ff6732fbeeedb692884c86f64241f83f0b61e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999997</th>\n",
       "      <td>547848b7217f199f450e4fae2b6a5bd20a48be91</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999998</th>\n",
       "      <td>07297e859807ed45651822fe31b7bbc48547fc5b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999999</th>\n",
       "      <td>b5dca6dce3421cb06e45282404b33d89e6648f1c</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         device_id first\n",
       "0         7cd2e83fb6522438401ce0660ea33df317643282     7\n",
       "1         dc0a36109d57c76f18ef47ff1f03ed84adcf7c37     d\n",
       "2         c98398a8467c710fec4f568fa89052dd73f8e251     c\n",
       "3         6683b63b4e74d5086ea43277427c2c4e5895f3a1     6\n",
       "4         2be582b3bc39baa328314b262a4c0b235c6cbd31     2\n",
       "...                                            ...   ...\n",
       "11999995  ec11eff98662f443f429a6c9806bba653297735c     e\n",
       "11999996  1e8ff6732fbeeedb692884c86f64241f83f0b61e     1\n",
       "11999997  547848b7217f199f450e4fae2b6a5bd20a48be91     5\n",
       "11999998  07297e859807ed45651822fe31b7bbc48547fc5b     0\n",
       "11999999  b5dca6dce3421cb06e45282404b33d89e6648f1c     b\n",
       "\n",
       "[12000000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf['first'] = pdf.device_id.astype(str).str[0]\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6dd9960-f20e-4bd8-9d6e-adbc6a3d74c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 265 ms, total: 12.8 s\n",
      "Wall time: 12.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12000000</td>\n",
       "      <td>2.286337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200000</td>\n",
       "      <td>0.230232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>0.031176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12000</td>\n",
       "      <td>0.004522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.002058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>120</td>\n",
       "      <td>0.001851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0.001814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size      time\n",
       "0  12000000  2.286337\n",
       "1   1200000  0.230232\n",
       "2    120000  0.031176\n",
       "3     12000  0.004522\n",
       "4      1200  0.002058\n",
       "5       120  0.001851\n",
       "6        12  0.001814"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "size_time = []\n",
    "size = len(pdf)\n",
    "\n",
    "while size > 1:\n",
    "    sample = pdf.sample(size)\n",
    "    start = time.time()\n",
    "    sample.groupby('first').agg({'device_id': 'count'})\n",
    "    end = time.time()\n",
    "    size_time.append({\n",
    "        'size': size,\n",
    "        'time': end - start,\n",
    "    })\n",
    "    size = size // 10\n",
    "\n",
    "pdf_size_time = pd.DataFrame(size_time)\n",
    "pdf_size_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3970287a-a019-4388-bc9f-1086d11ac390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = pdf_size_time.plot.bar(x='size', y='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04922d-1709-4591-b827-01af9ac62c88",
   "metadata": {},
   "source": [
    "Even in memory, the time it takes to aggregate the counts is not negligible, and it would worsen with the larger size.\n",
    "\n",
    "Depending on the available computing resources, this may vary. But after a certain threshold, it exhibits a linear growth of time needed to operate.\n",
    "\n",
    "Now let's try with Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0029b07e-5a97-450f-9598-53a9f2576357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           device_id|first|\n",
      "+--------------------+-----+\n",
      "|47afe935b8f45243f...|    4|\n",
      "|9dcc4074aae530935...|    9|\n",
      "|6f1cc31ab0b8aeac8...|    6|\n",
      "|1255fd9b34f4cf3f9...|    1|\n",
      "|2961e4f3c3a6b9937...|    2|\n",
      "|b1039161a48385115...|    b|\n",
      "|56da382007ec9d08e...|    5|\n",
      "|4ac4d0dc3171da9a3...|    4|\n",
      "|98973d79af19fbc0d...|    9|\n",
      "|6e27e950fc31b25a3...|    6|\n",
      "|32bd28251b8c8289e...|    3|\n",
      "|1c53b11a82ecc3ef3...|    1|\n",
      "|95fccb3112410f759...|    9|\n",
      "|1c330093580a2f39e...|    1|\n",
      "|28f18e96294d898b7...|    2|\n",
      "|33d8454e5ca202527...|    3|\n",
      "|3c00225c2bccb6d0f...|    3|\n",
      "|155bdf605c6a932db...|    1|\n",
      "|f44773cb771118ec9...|    f|\n",
      "|0ad04a18e2df495bd...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('first', df.device_id.substr(0, 1))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402bc62-3733-46ca-b263-f6c722349e50",
   "metadata": {},
   "source": [
    "From the above examples, we already know that Spark DataFrames, due to an entirely different and more complex mechanism compared to the more direct in-memory model that Pandas employs, the sampling process may be more time-consuming. Therefore the runtime of the entire while loop logic may take much longer, but the aggregation portion is captured precisely like its Pandas counterpart.\n",
    "\n",
    "Fortunately, we can instruct Spark to initiate caching to minimize roundtrips between disks and the memory space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89a26357-5f3e-4b62-a96a-9d61b3f97dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.cache()  # prepare the cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb98a2bd-699b-4a08-975b-eb651cce5f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 253 ms, sys: 161 ms, total: 414 ms\n",
      "Wall time: 27.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12000000</td>\n",
       "      <td>1.865914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200731</td>\n",
       "      <td>0.853110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119643</td>\n",
       "      <td>0.877328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12173</td>\n",
       "      <td>1.012259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1162</td>\n",
       "      <td>1.152587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>120</td>\n",
       "      <td>0.793524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0.783296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size      time\n",
       "0  12000000  1.865914\n",
       "1   1200731  0.853110\n",
       "2    119643  0.877328\n",
       "3     12173  1.012259\n",
       "4      1162  1.152587\n",
       "5       120  0.793524\n",
       "6        12  0.783296"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "size_time = []\n",
    "count = 12000000  # we already know the total record count\n",
    "size = count\n",
    "\n",
    "while size > 1:\n",
    "    sample = df.sample(size / count)\n",
    "    _count = sample.count()\n",
    "    start = time.time()\n",
    "    sample.groupby('first').agg({'device_id': 'count'}).collect()  # collect is used to emulate full data scan/process\n",
    "    end = time.time()\n",
    "    size_time.append({\n",
    "        'size': _count,\n",
    "        'time': end - start,\n",
    "    })\n",
    "    size = size // 10\n",
    "\n",
    "df_size_time = pd.DataFrame(size_time)\n",
    "df_size_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ce5bc23-216e-4a32-ac81-b26e11904e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = df_size_time.plot.bar(x='size', y='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbc8ce-c65a-4519-a816-407b498df218",
   "metadata": {},
   "source": [
    "While it is significantly slower to bootstrap the samples, the aggregation shows a glimpse of Spark's true strength (or the distributed filesystem and the MapReduce model behind it). \n",
    "\n",
    "The time it takes to compute the aggregation can be nearly uniform regardless of the given sample size. This scalability characteristic becomes more prominent and essential as a tool to process data when the sample size goes beyond a single machine's capacity, much like the situation that Google encountered in the early 2000s.\n",
    "\n",
    "Since its inception, Apache Spark has stayed current thanks to the contributions from open-source participants. For example, it has stream processing support for a more incremental instead of a large batch of MapReduce tasks to achieve near real-time analytics and more.\n",
    "\n",
    "![spark more](https://user-images.githubusercontent.com/2837532/123450843-24e45600-d5ab-11eb-86d7-e5584adf42f9.png)\n",
    "\n",
    "## Remarks\n",
    "\n",
    "We can leverage techniques such as multiprocessing, multithreading, or coroutines to expedite data processing.\n",
    "\n",
    "When the data size is much more than a single machine can handle, tools such as Apache Spark become vital to get the job done in a timely and cost-effective manner.\n",
    "\n",
    "![EMR](https://user-images.githubusercontent.com/2837532/123005848-c89fed00-d384-11eb-8967-2e78faf718f2.png)\n",
    "\n",
    "## References\n",
    "\n",
    "* [Apache Spark](https://spark.apache.org/) and its [PySpark interface](https://spark.apache.org/docs/latest/api/python/index.html)\n",
    "* [Python Coroutines and Tasks](https://docs.python.org/3/library/asyncio-task.html)\n",
    "* [Part 11 - Work with SQL](../11-work-with-sql.ipynb)\n",
    "* [Part 12 - Generate Data](../12-generate-data.ipynb)\n",
    "* [Part 13 - The Power of Parallel Processing feat. multithreading and multiprocessing](../13-data-processing.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa978d-8fc7-4ec8-966f-0aa87060138b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
