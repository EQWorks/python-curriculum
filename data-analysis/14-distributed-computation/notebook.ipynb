{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12adacc-007f-40fb-a86e-37ec50ac2b6f",
   "metadata": {},
   "source": [
    "# Distributed Computation\n",
    "\n",
    "## Quick Recap - Multiprocessing vs. Multithreading\n",
    "\n",
    "Multiprocessing can utilize multiple CPU cores, thus achieving a more authentic sense of parallel computation. However, multiprocessing suffers when they need to share a common memory space.\n",
    "\n",
    "On the other hand, multithreading can share a common memory space and achieve a more loose sense of parallel computation. As a result, multithreading is more like hyper-jumping through multiple queues (within the same process) while waiting for each particular thread's turn:\n",
    "\n",
    "1. When it is one specific thread's turn, it will acquire the Global Interpreter Lock (GIL) to control the memory space _and_ the CPU core until it finishes its designated computation or hits another \"busy-waiting\" block (such as I/O actions).\n",
    "2. Then, the loop releases the GIL and lets the jump proceed (context-switch) to the following thread.\n",
    "3. Rinse and repeat (until done).\n",
    "\n",
    "You can revisit [part 13](../13-data-processing.ipynb) for more details on this subject.\n",
    "\n",
    "### Asynchronous I/O Loops, and Multithreading's Little Brother - Coroutines\n",
    "\n",
    "Both multiprocessing and multithreading require dedicated hardware or operating system support. As software technologies mature, engineers started to explore capabilities within the application layer itself. As a result, the same conceptual model of multithreading gets a new interpretation within the programming stack (such as Python), giving more direct control to the program within the runtime instead of relying on the OS mechanism to switch context. The term [_Coroutine_](https://en.wikipedia.org/wiki/Coroutine), first coined in 1958, is a materialization of the concept of lightweight threads.\n",
    "\n",
    "Both multithreading and coroutine techniques are suitable for I/O focused tasks, such as reading files from a disk or making HTTP requests. However, coroutines tend to require less computing resource overhead than threads by giving up some performance benefit from tapping into the more OS-native mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e3a796-c985-4659-a933-2d4dde6a1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "\n",
    "\n",
    "# 5 requests, each with delays ranging from 1-3 seconds\n",
    "reqs = [\n",
    "    f'https://httpbin.org/delay/{random.randint(1, 3)}'\n",
    "    for _ in range(5)\n",
    "]\n",
    "\n",
    "def get_sync():\n",
    "    all_data = []\n",
    "    for req in reqs:\n",
    "        res = requests.get(req)\n",
    "        all_data.append(res.json())\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8483a5c-e857-41d8-8191-14e5ff96132a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.2 ms, sys: 10.3 ms, total: 94.5 ms\n",
      "Wall time: 10.5 s\n",
      "{'args': {}, 'data': '', 'files': {}, 'form': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.25.1', 'X-Amzn-Trace-Id': 'Root=1-60d65367-3503a36e56f6d53f2ca31a75'}, 'origin': '107.179.188.69', 'url': 'https://httpbin.org/delay/1'} 5\n"
     ]
    }
   ],
   "source": [
    "%time res = get_sync()\n",
    "print(res[-1], len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107f433-9bc4-4b0f-9dd1-77603dfaa07a",
   "metadata": {},
   "source": [
    "In Python, [the `asyncio` module](https://docs.python.org/3/library/asyncio.html) provides a standard set of APIs for its users to utilize coroutines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b010385-d4ff-4870-9e0e-4f1164dc465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "async def get(session, url):\n",
    "    res = await session.request('GET', url=url)\n",
    "    data = await res.json()\n",
    "    return data\n",
    "\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for req in reqs:\n",
    "            tasks.append(get(session, url=req))\n",
    "\n",
    "        all_data = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7ffa8-f260-4c4e-ae5f-ac3d4c6eb658",
   "metadata": {},
   "source": [
    "There are two caveats about utilizing `asyncio` in the Jupyter Notebook environment:\n",
    "1. We cannot use the %time magic command for async functions.\n",
    "2. We cannot initiate an explicit event loop (it's already in one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f338e2f-1951-4558-bf6d-531bd7becb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 seconds\n",
      "{'args': {}, 'data': '', 'files': {}, 'form': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Host': 'httpbin.org', 'User-Agent': 'Python/3.8 aiohttp/3.7.4.post0', 'X-Amzn-Trace-Id': 'Root=1-60d65368-2ca9bf10688e9d1638a9e1bb'}, 'origin': '107.179.188.69', 'url': 'https://httpbin.org/delay/1'} 5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# loop = asyncio.get_event_loop()\n",
    "# loop.run_until_complete(main())\n",
    "start = time.time()\n",
    "res = await main()\n",
    "print(round(time.time() - start, 1), 'seconds')\n",
    "print(res[-1], len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866076f-3616-4e9b-8b48-2c07c6f5f627",
   "metadata": {},
   "source": [
    "Let's use the responses to verify what the delays were in the API calls by using functional techniques `map()` and `reduce()` to extract delays (in seconds) and sum them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920e2588-47d2-44a4-a979-2f14739fe203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 1, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delay_mapper(url):\n",
    "    return int(url.split('/')[-1])\n",
    "\n",
    "delays = list(map(delay_mapper, reqs))\n",
    "delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658e2b6b-5d19-44eb-a486-b6841d3bf1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def delay_reducer(left, right):\n",
    "    return left + right\n",
    "\n",
    "# same as calling `sum(delays)`\n",
    "total_delay = reduce(delay_reducer, delays, 0)\n",
    "total_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be12faf4-d0ea-4921-b5e1-01a864f7aa8b",
   "metadata": {},
   "source": [
    "The total theoretical delay matches our observation from the synchronous process, while the _maximum_ from individual delays matches what we saw from the asynchronous version.\n",
    "\n",
    "## MapReduce - Distributing Computing Resources\n",
    "\n",
    "Recall one of the most critical disadvantages of multiprocessing - the lack of shared memory space. One workaround of such an issue is to leverage the filesystem as an inter-process data pool so that multiple processes can simultaneously read and write to it, such as a local SQLite database, as demonstrated in [part 11](../11-work-with-sql.ipynb).\n",
    "\n",
    "Suppose we extend this problem to a larger scale, where the dataset we want to work with exceeds the available memory space and is impossible to efficiently store (or at all) on the disk of a single machine. In that case, we need to revisit viable solutions.\n",
    "\n",
    "The MapReduce model is a _divide and conquer_ strategy applying and extending the functional programming concepts of `map()` and `reduce()`. Through this model, a large dataset is dissected and distributed through a mapping procedure onto a multitude of computational nodes to parallelize the computation of the smaller portion, then reducing the resulting subsets back to fewer nodes until the cluster concludes the outcome.\n",
    "\n",
    "A simple demonstration of how the MapReduce model helps with tallying the number of occurrences of unique words of a given paragraph:\n",
    "\n",
    "![MapReduceImage](https://user-images.githubusercontent.com/58446818/123367276-adc9a600-d547-11eb-9a37-5b91ce2eb090.png)\n",
    "\n",
    "This model allows batch data processing to have a near-infinite capacity and a relatively cost-effective way to speed up the process.\n",
    "\n",
    "It is worth noting that the development of cheaper and faster hard drives, especially the more widespread adoption of SSDs (solid-state drive), plays a vital role in enabling distributed computation.\n",
    "\n",
    "The MapReduce model was first pioneered [by Google](https://research.google/pubs/pub62/) in 2004 to resolve the practical problem of exponentially growing datasets for computing their search indexes. Then many have adopted and contributed toward the technology's development and evolution through the open-source community.\n",
    "\n",
    "### Apache Spark™\n",
    "\n",
    "Apache Spark is such an open-source framework that came around 2014 that provides an elegant and unified abstraction on top of proven technologies such as SQL to enable large-scale data processing that can efficiently utilize from a single machine to \"multiple clouds.\" You can find more comprehensive examples in [Spark's DataFrame usage notebook](./spark-dataframe-usage.ipynb).\n",
    "\n",
    "For the sake of simplicity, we will demonstrate its distributed nature on multiple cores of a single machine. First, obtain the number of CPU core:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2d71cc-fdac-4c6e-985f-8a7f784b37a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "CORES = multiprocessing.cpu_count()\n",
    "CORES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ec5e4-c646-4357-b372-78c5d1d4e8e7",
   "metadata": {},
   "source": [
    "Borrowing from [part 12](../12-generate-data.ipynb), where we attempted to generate random and hashed device IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab89d25-26a1-4bf9-841b-23005c22b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly from Part 12 - Generate data\n",
    "from uuid import uuid4\n",
    "from hashlib import sha1\n",
    "\n",
    "\n",
    "def gen_device_ids(count: int = 20_000) -> list:\n",
    "    device_ids = []\n",
    "    for _ in range(count):\n",
    "        device_ids.append(str(uuid4()))\n",
    "    # hash\n",
    "    return [sha1(x.encode()).hexdigest() for x in device_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5ea06-9dba-44f2-a653-9c2856366b4d",
   "metadata": {},
   "source": [
    "Let's generate a relatively large batch of device IDs, say 1 million times the number of `CORES`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a7c6a45-9867-4cff-9f28-c58b3025ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53 s, sys: 5.27 s, total: 58.2 s\n",
      "Wall time: 58.4 s\n"
     ]
    }
   ],
   "source": [
    "%time device_ids = gen_device_ids(count=1_000_000 * CORES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8c3ce-3642-46b8-800b-418b0c753344",
   "metadata": {},
   "source": [
    "Due to the single iterative process, the time it takes is quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58a5abe5-5615-46c8-947d-e04def2c91cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['faf75f0719930eb447c68ec74e0225254f0cc911',\n",
       " 'ff4dcbe1027357930fe3e4abfd2bb5891c364c5f',\n",
       " '8dbcc1968dfae0d06d7ce767738a4bf3c82c3b55',\n",
       " 'd497ace69fe9a24fb59310b922ba0cbea4af3e77',\n",
       " 'f9f21376ce5f3e231e489a823d81fd1049c53093',\n",
       " '49de1f5444baee558f2acbae409605db7a046fcd',\n",
       " '1a9a98be124b2bc8c0de7b0cd171c9882705b9b2',\n",
       " 'e21c67ff2f79c012d204e0c2f7d96ef66d0b7894',\n",
       " '22bef4a0ebfa4004f655a7c053ff472f5d060ee5',\n",
       " 'c719055b1de05052e7901a5199c7dc4d9ccd4a66']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time device_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10f65615-fedf-40cf-a8d7-f589c60f64be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time len(device_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481733f-e3f3-4678-a2d9-7af6a53e8b54",
   "metadata": {},
   "source": [
    "But since the list is already in memory, it takes very little time to read them out.\n",
    "\n",
    "Let's try the same device ID generation with Spark in a distributed manner. We will initiate a Spark session with a local \"master\" that takes advantage of the number of `CORES` we have obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30282e77-5efc-45fb-8753-e1a006c4051c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://runzhoudembp.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[12]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x14cf17820>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(f'local[{CORES}]').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d1fb0-1a29-45a8-a632-945ed4a6623a",
   "metadata": {},
   "source": [
    "The Spark UI, which runs on the `localhost`, is handy for monitoring and more.\n",
    "\n",
    "![Spark UI](https://user-images.githubusercontent.com/2837532/122995953-46a9c700-d378-11eb-84a7-50917d34b7be.png)\n",
    "\n",
    "The first approach involves a core concept and building block of Spark, known as Resilient Distributed Datasets (`RDD`s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb80f2ce-34df-4ab1-b043-4e6585ada283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 ms, sys: 1.48 ms, total: 2.84 ms\n",
      "Wall time: 3.31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def mapper(count):\n",
    "    return [(d,) for d in gen_device_ids(count)]\n",
    "\n",
    "# a list of [1_000_000, ..., 1_000_000], where the length is the number of CORES\n",
    "counts = [1_000_000] * CORES\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(counts).flatMap(mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e05c8-c9ee-46e5-8301-0f3dbe2c15b5",
   "metadata": {},
   "source": [
    "The action takes a context from the available Spark session, scheduled to parallelize over a list of 1 million counts, where the list length is the number of `CORES`. Then we instruct the parallelization to map the Python list over a `mapper` function that takes the individual count and generates a list of device IDs (single element tuples). The `.flatMap` method is a convenient layer to ensure the resulting dataset as a single-tier list of device IDs instead of a list of (number of `CORES`) lists.\n",
    "\n",
    "Notice the time it takes to schedule is negligible, as Spark takes a _lazy_ approach to preserve computing resources until the computation is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0df7f70-b1ee-44fe-af21-89c21df0221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.07 ms, sys: 2.38 ms, total: 7.45 ms\n",
      "Wall time: 5.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cb4d2c9c0196e885d3efcb042aaf74b85cce8194',),\n",
       " ('44f4f25f559dfaf5bb921cf6e77c6441047591b0',),\n",
       " ('45ee04e6cb553e964cbb7eaff01e6a004db283b3',),\n",
       " ('1c9e57771e4ce8d1064bdc76782d3b4853aadbbc',),\n",
       " ('afc5df445f61d868e451b4bf4cf56de2f54d85cc',),\n",
       " ('9aa62f29e316c14bba22fc54fa73f8f40a9aca22',),\n",
       " ('30783d5f44e30f12bdabbf670afcb322fea293b5',),\n",
       " ('e70349517a223d9d1b8aa901983d78baa9210cb3',),\n",
       " ('582a6343d6192f0f52eefb7b72435f697364a2e2',),\n",
       " ('c7f4d791ecb50c6cb97d265f4950793633ac2ec8',)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22793df6-78be-48e4-8b5c-87964f7230fc",
   "metadata": {},
   "source": [
    "Indeed, when we instruct to take the first ten values from the RDD, Spark would start the computation (and more). If we go back to the Spark UI, it may better picture what Spark has done under the hood.\n",
    "\n",
    "![RDD take](https://user-images.githubusercontent.com/2837532/122997519-16fbbe80-d37a-11eb-8704-5c520019e161.png)\n",
    "\n",
    "Conceptually, the workflow is as the following:\n",
    "1. Generate the device IDs leveraging multiple `CORES` in parallel.\n",
    "2. Persist device IDs as RDD into distributed blocks on disk. They have also replicated automatically across available distributions to support further parallelized processes. Spark also records other necessary metadata, such as the order of values, to ensure that computations that require strict ordering do not get affected.\n",
    "3. Draw the first ten values from the RDD files and populates them into the Python process that runs this Notebook.\n",
    "\n",
    "This workflow means that while it is significantly faster to generate the device IDs than the single process iterative approach, it is much slower to read. It involves a more complex trip to read from files while ensuring the order of values is intact.\n",
    "\n",
    "`RDD`s can be cached into memory (the part that has been computed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cedb132-2bc6-443f-a261-b75ffc8b3179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.99 ms, sys: 1.88 ms, total: 4.87 ms\n",
      "Wall time: 7.01 ms\n"
     ]
    }
   ],
   "source": [
    "%time rdd = rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26a2c8a4-686e-42a1-b52c-241eff3f4f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 ms, sys: 1.95 ms, total: 5.35 ms\n",
      "Wall time: 5.17 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('de813357f09054d03639b0ef9f364f872aaa6c80',),\n",
       " ('699730584d970695c230a1b6cfbc9cb65b792bc1',),\n",
       " ('cd44f19519fd7bf2d9cd6e289dc68c53262bfd24',),\n",
       " ('5ab59ba321c45edbcb00fc81e3670731eafe4096',),\n",
       " ('500e58386fe4f723fb50969f2a6c94650c6e6393',),\n",
       " ('84a8b35e824bf78146fb2311314a107b6c468f1c',),\n",
       " ('94a3879a26eec97bf456d649332b02dff99b185d',),\n",
       " ('69996c4fc9fb605978167ac562bd375d859b0318',),\n",
       " ('6c5be158c27fdd4b83d48ecf8b9a0d407cc52f6f',),\n",
       " ('30b2eaa0f18a9444d9d2b5c317f3800c18012916',)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ef033-5f26-493b-93e0-a05d53a21f10",
   "metadata": {},
   "source": [
    "Because it's cached, the consecutive call would be much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21fcfe69-6f6b-4cd7-ad88-193ee7688254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.35 ms, sys: 2.07 ms, total: 5.42 ms\n",
      "Wall time: 19.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('de813357f09054d03639b0ef9f364f872aaa6c80',),\n",
       " ('699730584d970695c230a1b6cfbc9cb65b792bc1',),\n",
       " ('cd44f19519fd7bf2d9cd6e289dc68c53262bfd24',),\n",
       " ('5ab59ba321c45edbcb00fc81e3670731eafe4096',),\n",
       " ('500e58386fe4f723fb50969f2a6c94650c6e6393',),\n",
       " ('84a8b35e824bf78146fb2311314a107b6c468f1c',),\n",
       " ('94a3879a26eec97bf456d649332b02dff99b185d',),\n",
       " ('69996c4fc9fb605978167ac562bd375d859b0318',),\n",
       " ('6c5be158c27fdd4b83d48ecf8b9a0d407cc52f6f',),\n",
       " ('30b2eaa0f18a9444d9d2b5c317f3800c18012916',)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eac8f8-acc2-48f9-8c6c-2e2077667646",
   "metadata": {},
   "source": [
    "The following illustration shows the workflow of RDD operations:\n",
    "\n",
    "![RDD workflow](https://user-images.githubusercontent.com/2837532/123459338-28c8a600-d5b4-11eb-8ac8-c13c22456d5f.png)\n",
    "\n",
    "The Spark DataFrame builds on top of RDDs (and other filesystem abstractions or \"Data Lakes\"):\n",
    "\n",
    "![spark dataframe](https://user-images.githubusercontent.com/2837532/123487976-0008d680-d5dd-11eb-8abd-076bd3f9420f.png)\n",
    "\n",
    "The PySpark API offers a convenient pathway to get the DataFrame instance from existing RDDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79918937-4a6b-43ee-a35a-ad09406581d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.92 ms, sys: 2.7 ms, total: 9.62 ms\n",
      "Wall time: 37.5 ms\n"
     ]
    }
   ],
   "source": [
    "%time df = rdd.toDF(['device_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80978d82-77ca-4c72-a07e-3d107e6208c3",
   "metadata": {},
   "source": [
    "This step reveals the trade-off more prominently, where the time it takes to operate on the distributed dataset can be much more time consuming than its in-memory counterpart, where we can take the in-memory `list` of `device_ids` and convert it into a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "668cfff9-de2a-41b4-a72d-fa13cc48d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14282bfc-a1f2-41a7-8e23-95a6e81a0804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 559 ms, sys: 203 ms, total: 762 ms\n",
      "Wall time: 761 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faf75f0719930eb447c68ec74e0225254f0cc911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff4dcbe1027357930fe3e4abfd2bb5891c364c5f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8dbcc1968dfae0d06d7ce767738a4bf3c82c3b55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d497ace69fe9a24fb59310b922ba0cbea4af3e77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f9f21376ce5f3e231e489a823d81fd1049c53093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999995</th>\n",
       "      <td>ee655ddb6558f64222bbe736e6556504a7fdf8a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999996</th>\n",
       "      <td>13b7106737c3e3bd2aebd0a947855fcd8b42103d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999997</th>\n",
       "      <td>7dd2916be62fadd01e207c8ccc0b209303e78834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999998</th>\n",
       "      <td>48a09b7001eb18c5be7a60469cba9448574159a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999999</th>\n",
       "      <td>8f99202b7c985f12cfe18ef2660156521dfbe85b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         device_id\n",
       "0         faf75f0719930eb447c68ec74e0225254f0cc911\n",
       "1         ff4dcbe1027357930fe3e4abfd2bb5891c364c5f\n",
       "2         8dbcc1968dfae0d06d7ce767738a4bf3c82c3b55\n",
       "3         d497ace69fe9a24fb59310b922ba0cbea4af3e77\n",
       "4         f9f21376ce5f3e231e489a823d81fd1049c53093\n",
       "...                                            ...\n",
       "11999995  ee655ddb6558f64222bbe736e6556504a7fdf8a5\n",
       "11999996  13b7106737c3e3bd2aebd0a947855fcd8b42103d\n",
       "11999997  7dd2916be62fadd01e207c8ccc0b209303e78834\n",
       "11999998  48a09b7001eb18c5be7a60469cba9448574159a5\n",
       "11999999  8f99202b7c985f12cfe18ef2660156521dfbe85b\n",
       "\n",
       "[12000000 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pdf = pd.DataFrame(device_ids, columns=['device_id'])\n",
    "\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80250bd-5186-48cc-8fa1-d68d777000dc",
   "metadata": {},
   "source": [
    "Bearing the same understanding, the Spark DataFrame would be slower to read due to the round-trip it takes to the distributed disk blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eb420e0-3da9-438a-ba00-769fd74c20bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           device_id|\n",
      "+--------------------+\n",
      "|442b7604e1123a99c...|\n",
      "|41ecf59691da741ec...|\n",
      "|e1b3f55b516cc214c...|\n",
      "|ff46b87c1778607d4...|\n",
      "|6e7ba4939a605546b...|\n",
      "|2eed17f704bccaa9d...|\n",
      "|5ac4f8d7b878c21db...|\n",
      "|e79a26317daa7bfaf...|\n",
      "|ed9245213772d1c68...|\n",
      "|06a2ceca9f35b2dbe...|\n",
      "|dca88f28d8bc02b91...|\n",
      "|09e091aade6ad23e7...|\n",
      "|fc393f6674fd94b5b...|\n",
      "|c77bb93f8366c6ab9...|\n",
      "|f3fcdcd556a3b5344...|\n",
      "|b82ece4c55e8805b3...|\n",
      "|a9f969415f5ea01e7...|\n",
      "|54a6e5a2b59d295ba...|\n",
      "|21f05fb3ae5b3a56d...|\n",
      "|02806a1a263b1ccda...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 1.13 ms, sys: 1.25 ms, total: 2.38 ms\n",
      "Wall time: 711 ms\n"
     ]
    }
   ],
   "source": [
    "%time df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e93dcb6-db18-42ec-b2ba-b7773b3c00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 420 ms, sys: 8.84 ms, total: 428 ms\n",
      "Wall time: 427 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device_id    12000000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "418fede8-ede8-4edc-ad5d-db1c7e198864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 ms, sys: 1.74 ms, total: 3.73 ms\n",
      "Wall time: 17 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ede288-46d0-4cb0-8988-422d9d9f5e54",
   "metadata": {},
   "source": [
    "Spark would attempt optimization not to scan the full range of dataset when invoking partial readings such as `rdd.take()` or `df.show()`, but suffers a full-range scan when it needs to count the accurate number of items, hence the much longer duration. It can also benefit from the similar cache mechanism seen in its RDD counterpart to obtain partial speedup.\n",
    "\n",
    "We can also build Spark DataFrames through the help of concatenating existing Pandas DataFrames. Much like how the Pandas DataFrame offers a set of convenient functions and methods to work with SQL, Spark (or, more accurately, PySpark) also provides easy access for Pandas DataFrames.\n",
    "\n",
    "Spark's backend is mainly implemented in [the Scala programming language](https://scala-lang.org/) and runs on the JVM (Java virtual machine) runtime. Its Python interface is enabled through a chain of clever abstractions and techniques to ensure that both the Python data structures and functions can execute effectively and efficiently.\n",
    "\n",
    "Below is an alternative approach for the device ID generation task by leveraging the robust support of Spark's native support to interface with Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bca3108-7df8-4744-adcb-26a2e221a769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.16 ms, sys: 1.19 ms, total: 7.35 ms\n",
      "Wall time: 27.5 ms\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(i,) for i in range(CORES)], ['cluster'])\n",
    "\n",
    "def _gen(df):\n",
    "    device_ids = gen_device_ids(count=1_000_000)\n",
    "    pdf = pd.DataFrame(device_ids, columns=['device_id'])\n",
    "    pdf['cluster'] = df['cluster']\n",
    "    return pdf.reset_index()\n",
    "\n",
    "def gen_device_ids_udf(df):\n",
    "    output = []\n",
    "    for _, row in df.iterrows():\n",
    "        pdf = _gen(df)\n",
    "        output.append(pdf)\n",
    "\n",
    "    return pd.concat(output)\n",
    "\n",
    "\n",
    "schema = 'index long, cluster long, device_id string'\n",
    "%time df = df.groupby('cluster').applyInPandas(gen_device_ids_udf, schema=schema).drop('cluster', 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe3c37-9cf6-439a-8b57-fac23ba580f5",
   "metadata": {},
   "source": [
    "A similar parallelization principle from the RDD approach applies here. Conceptually, there is a \"hack\" around the `.groupby()` mechanism, which enables the parallelization against the number of `CORES`.\n",
    "\n",
    "Like the RDD approach, the task scheduling does not take long, as we have yet to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d620162-9d26-46d5-871d-82b987b73541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           device_id|\n",
      "+--------------------+\n",
      "|1aac81ea12d8a37f5...|\n",
      "|e8a7399af6c47dec4...|\n",
      "|950f89df5479a0ba3...|\n",
      "|b3d6d0088e24e96d3...|\n",
      "|0a6de7414c6c24d11...|\n",
      "|3b10fb2a96d756414...|\n",
      "|eb53e0da836c0ccec...|\n",
      "|82c39a9e8e130448b...|\n",
      "|c82214b00d0a4a7f3...|\n",
      "|dc18ffe54f7742c75...|\n",
      "|fb17ce73dd7ab76a5...|\n",
      "|44b9712608651c48e...|\n",
      "|88aee329b4e8f6e75...|\n",
      "|bc362f2d09c3e3d7d...|\n",
      "|4811a2391a1388751...|\n",
      "|da7f793c05f5dfb0e...|\n",
      "|5ad220dca210a3a5d...|\n",
      "|28f3abf80a2928fe2...|\n",
      "|b1f95a7c780fbf683...|\n",
      "|562c864172299b0c7...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 3.09 ms, sys: 2.62 ms, total: 5.71 ms\n",
      "Wall time: 5.91 s\n"
     ]
    }
   ],
   "source": [
    "%time df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab32a57-cb9e-4c90-b769-0a5cdfd43f1d",
   "metadata": {},
   "source": [
    "Since this approach involves a more pronounced mapping process abstracted by the `.groupby` method, the underlying workflow can be a bit more interesting to observe:\n",
    "\n",
    "![group by](https://user-images.githubusercontent.com/2837532/123001100-5b895900-d37e-11eb-8b2a-db3fa40caaba.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5144c54a-b74a-43d4-94fc-953e27d84f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 ms, sys: 9.92 ms, total: 27.3 ms\n",
      "Wall time: 12.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908a266-8738-43b2-b96f-22cf114c11d8",
   "metadata": {},
   "source": [
    "Read access and the time consumption behaviours are within our expectations.\n",
    "\n",
    "Let's attempt to perform some actual analysis of the overall dataset, such as counting the number of device IDs by their first characters.\n",
    "\n",
    "We'll start with the Pandas DataFrame, which is in-memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d87e7dc-8cb7-4dfc-8810-993e34d40848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faf75f0719930eb447c68ec74e0225254f0cc911</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff4dcbe1027357930fe3e4abfd2bb5891c364c5f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8dbcc1968dfae0d06d7ce767738a4bf3c82c3b55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d497ace69fe9a24fb59310b922ba0cbea4af3e77</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f9f21376ce5f3e231e489a823d81fd1049c53093</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999995</th>\n",
       "      <td>ee655ddb6558f64222bbe736e6556504a7fdf8a5</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999996</th>\n",
       "      <td>13b7106737c3e3bd2aebd0a947855fcd8b42103d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999997</th>\n",
       "      <td>7dd2916be62fadd01e207c8ccc0b209303e78834</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999998</th>\n",
       "      <td>48a09b7001eb18c5be7a60469cba9448574159a5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999999</th>\n",
       "      <td>8f99202b7c985f12cfe18ef2660156521dfbe85b</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         device_id first\n",
       "0         faf75f0719930eb447c68ec74e0225254f0cc911     f\n",
       "1         ff4dcbe1027357930fe3e4abfd2bb5891c364c5f     f\n",
       "2         8dbcc1968dfae0d06d7ce767738a4bf3c82c3b55     8\n",
       "3         d497ace69fe9a24fb59310b922ba0cbea4af3e77     d\n",
       "4         f9f21376ce5f3e231e489a823d81fd1049c53093     f\n",
       "...                                            ...   ...\n",
       "11999995  ee655ddb6558f64222bbe736e6556504a7fdf8a5     e\n",
       "11999996  13b7106737c3e3bd2aebd0a947855fcd8b42103d     1\n",
       "11999997  7dd2916be62fadd01e207c8ccc0b209303e78834     7\n",
       "11999998  48a09b7001eb18c5be7a60469cba9448574159a5     4\n",
       "11999999  8f99202b7c985f12cfe18ef2660156521dfbe85b     8\n",
       "\n",
       "[12000000 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf['first'] = pdf.device_id.astype(str).str[0]\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6dd9960-f20e-4bd8-9d6e-adbc6a3d74c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 171 ms, total: 12.3 s\n",
      "Wall time: 12.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12000000</td>\n",
       "      <td>2.425163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200000</td>\n",
       "      <td>0.265078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>0.028323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12000</td>\n",
       "      <td>0.004280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.002141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>120</td>\n",
       "      <td>0.001852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0.001830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size      time\n",
       "0  12000000  2.425163\n",
       "1   1200000  0.265078\n",
       "2    120000  0.028323\n",
       "3     12000  0.004280\n",
       "4      1200  0.002141\n",
       "5       120  0.001852\n",
       "6        12  0.001830"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "size_time = []\n",
    "size = len(pdf)\n",
    "\n",
    "while size > 1:\n",
    "    sample = pdf.sample(size)\n",
    "    start = time.time()\n",
    "    sample.groupby('first').agg({'device_id': 'count'})\n",
    "    end = time.time()\n",
    "    size_time.append({\n",
    "        'size': size,\n",
    "        'time': end - start,\n",
    "    })\n",
    "    size = size // 10\n",
    "\n",
    "pdf_size_time = pd.DataFrame(size_time)\n",
    "pdf_size_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3970287a-a019-4388-bc9f-1086d11ac390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = pdf_size_time.plot.bar(x='size', y='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04922d-1709-4591-b827-01af9ac62c88",
   "metadata": {},
   "source": [
    "Even in memory, the time it takes to aggregate the counts is not negligible, and it would worsen with the larger size.\n",
    "\n",
    "Depending on the available computing resources, this may vary. But after a certain threshold, it exhibits a linear growth of time needed to operate.\n",
    "\n",
    "Now let's try with Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0029b07e-5a97-450f-9598-53a9f2576357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           device_id|first|\n",
      "+--------------------+-----+\n",
      "|a745fef9b0a1a252e...|    a|\n",
      "|f2a547a065151a172...|    f|\n",
      "|5c48d473c3868d8bb...|    5|\n",
      "|a97aca58ac724f033...|    a|\n",
      "|6dccc5272741f2f37...|    6|\n",
      "|6198d6d45cc3ba30c...|    6|\n",
      "|43821de6853f8f5d8...|    4|\n",
      "|f285e548978363f22...|    f|\n",
      "|d1dd5b20dde6201e8...|    d|\n",
      "|5047532eb0b043545...|    5|\n",
      "|2990a8c249f2bcb5c...|    2|\n",
      "|cf36c8d508bf16c5a...|    c|\n",
      "|511ca6b3ebd44746b...|    5|\n",
      "|ac29dd206b18e2c3f...|    a|\n",
      "|74f0231a77514947b...|    7|\n",
      "|00b39376be3a98235...|    0|\n",
      "|e5049ce21fe4a3596...|    e|\n",
      "|cc65e4f70b574b92c...|    c|\n",
      "|8c65038388ee9f1b7...|    8|\n",
      "|29c52b7a56baffaee...|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('first', df.device_id.substr(0, 1))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402bc62-3733-46ca-b263-f6c722349e50",
   "metadata": {},
   "source": [
    "From the above examples, we already know that Spark DataFrames, due to an entirely different and more complex mechanism compared to the more direct in-memory model that Pandas employs, the sampling process may be more time-consuming. Therefore the runtime of the entire while loop logic may take much longer, but the aggregation portion is captured precisely like its Pandas counterpart.\n",
    "\n",
    "Fortunately, we can instruct Spark to initiate caching to minimize roundtrips between disks and the memory space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89a26357-5f3e-4b62-a96a-9d61b3f97dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb98a2bd-699b-4a08-975b-eb651cce5f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 251 ms, sys: 159 ms, total: 411 ms\n",
      "Wall time: 26.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12000000</td>\n",
       "      <td>1.133887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1199671</td>\n",
       "      <td>1.017156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119500</td>\n",
       "      <td>0.855499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12097</td>\n",
       "      <td>0.712340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1226</td>\n",
       "      <td>1.004409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>145</td>\n",
       "      <td>0.852818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>1.100920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size      time\n",
       "0  12000000  1.133887\n",
       "1   1199671  1.017156\n",
       "2    119500  0.855499\n",
       "3     12097  0.712340\n",
       "4      1226  1.004409\n",
       "5       145  0.852818\n",
       "6        11  1.100920"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "size_time = []\n",
    "count = df.count()\n",
    "size = count\n",
    "\n",
    "while size > 1:\n",
    "    sample = df.sample(size / count)\n",
    "    _count = sample.count()\n",
    "    start = time.time()\n",
    "    sample.groupby('first').agg({'device_id': 'count'}).collect()  # collect is used to emulate full data scan/process\n",
    "    end = time.time()\n",
    "    size_time.append({\n",
    "        'size': _count,\n",
    "        'time': end - start,\n",
    "    })\n",
    "    size = size // 10\n",
    "\n",
    "df_size_time = pd.DataFrame(size_time)\n",
    "df_size_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ce5bc23-216e-4a32-ac81-b26e11904e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = df_size_time.plot.bar(x='size', y='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbc8ce-c65a-4519-a816-407b498df218",
   "metadata": {},
   "source": [
    "While it is significantly slower to bootstrap the samples, the aggregation shows a glimpse of Spark's true strength (or the distributed filesystem and the MapReduce model behind it). \n",
    "\n",
    "The time it takes to compute the aggregation is nearly uniform regardless of the given sample size. This scalability characteristic becomes more prominent and essential as a tool to process data when the sample size goes beyond a single machine's capacity, much like the situation that Google encountered in the early 2000s.\n",
    "\n",
    "Since its inception, Apache Spark has stayed current thanks to the contributions from open-source participants. For example, it has stream processing support for a more incremental instead of a large batch of MapReduce tasks to achieve near real-time analytics and more.\n",
    "\n",
    "![spark more](https://user-images.githubusercontent.com/2837532/123450843-24e45600-d5ab-11eb-86d7-e5584adf42f9.png)\n",
    "\n",
    "## Remarks\n",
    "\n",
    "We can leverage techniques such as multiprocessing, multithreading, or coroutines to expedite data processing.\n",
    "\n",
    "When the data size is much more than a single machine can handle, tools such as Apache Spark become vital to get the job done in a timely and cost-effective manner.\n",
    "\n",
    "![EMR](https://user-images.githubusercontent.com/2837532/123005848-c89fed00-d384-11eb-8967-2e78faf718f2.png)\n",
    "\n",
    "## References\n",
    "\n",
    "* [Apache Spark](https://spark.apache.org/) and its [PySpark interface](https://spark.apache.org/docs/latest/api/python/index.html)\n",
    "* [Python Coroutines and Tasks](https://docs.python.org/3/library/asyncio-task.html)\n",
    "* [Part 11 - Work with SQL](../11-work-with-sql.ipynb)\n",
    "* [Part 12 - Generate Data](../12-generate-data.ipynb)\n",
    "* [Part 13 - The Power of Parallel Processing feat. multithreading and multiprocessing](../13-data-processing.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa978d-8fc7-4ec8-966f-0aa87060138b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
