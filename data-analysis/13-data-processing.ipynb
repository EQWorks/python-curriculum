{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "subject-audit",
   "metadata": {},
   "source": [
    "# The Power of Parallel Processing feat. multithreading and multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-forwarding",
   "metadata": {},
   "source": [
    "If you've worked with data, chances are you've had to deal with large datasets. and I mean LARGE!\n",
    "- insert image of something big\n",
    "\n",
    "When working with large datasets, one consequence is slower processing. To avoid spending lots of time waiting around, one way is to optimize the runtime of your code by using parallel processing. Parallel Processing is nothing new to us. Here's an example: Imagine you're an EQ data analyst and you find out there are 3 reports waiting to be done for a specific client. You can either do all 3 reports yourself one by one, or get 2 other data analysts to help you out and tackle one report each or take on one part of each report. Parallel processing is the second option.\n",
    "- insert image of this scenario\n",
    "\n",
    "Python offers this capability of parallel processing in 2 ways, through 2 modules: multiprocessing and threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-purchase",
   "metadata": {},
   "source": [
    "# What is multiprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-secondary",
   "metadata": {},
   "source": [
    "Python was designed this in mind: computers would only have one core. One process to be run by the one core at a time. Process is an executable program (so running some code) with its own memory space. But nowadays, that's not the case- computers have multiple cores. Since Python was not designed to have multiple processes run at the same time so there was potential of memory getting mixed up between the processes. It's like suddenly being able to read someone else's thoughts all of a sudden which can get chaotic. So Python has a Global Interpreter Lock (GIL) in place to help manage memory management and run one process with one core at a time. But this means Python doesn't effectively use all of the cores that are at its disposal. That's where multiprocessing comes in: create multiple processes with its own memory space for each core.\n",
    "- insert diagram\n",
    "\n",
    "Multiprocessing bypasses GIL and uses all cores (one process per core). You'll see the speed difference in a bit through an example with pandas and Modin. An analogy of this would be 3 data analysts working on 1 report as opposed to 1 data analyst working on 3 reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-petroleum",
   "metadata": {},
   "source": [
    "# When would you use multiprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-phase",
   "metadata": {},
   "source": [
    "This method is great for CPU-intensive processes like deep analyses, heavy filtering and data manipulation. By having multiple processes, you lighten the load instead of one process doing all of the work, like in the data analyst scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-harrison",
   "metadata": {},
   "source": [
    "# Modin: An example of multiprocessing\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-treasure",
   "metadata": {},
   "source": [
    "# You mentioned threading, what is multithreading?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-conjunction",
   "metadata": {},
   "source": [
    "If the tasks aren't CPU-intensive such as data fetching and other I/O operations like web scraping, we can leverage threading. Threads are components of a process that work in parallel and share the same memory space. As mentioned earlier, a process is executable code with its own memory space. When data fetching, one process is enough (instead of multiple processes) since the processor will be waiting around for data to come back so we can fetch data in parallel by using threads. Python will execute one thread at a time utilizing the one process.\n",
    "\n",
    "An example is: think about multiple people editing a google document in real-time. The google document is one memory space and multiple people are adding text to this document. Think of each person as a thread. In our data analyst example, it's like 3 analysts working on one report to speed up the process. In multiprocessing, it'd be like multiple google documents being edited by 1 person each or in our data analyst example, 1 data analyst doing 1 report each.\n",
    "\n",
    "- insert image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-description",
   "metadata": {},
   "source": [
    "# So when would we use threading?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-partner",
   "metadata": {},
   "source": [
    "1. Creating processes can be a bit slow so if the code that you are running is not CPU-intensive such as data fetching, threading is a great option. Creating threads is much more lightweight than creating processes. \n",
    "- insert image\n",
    "2. Sharing objects is easier between threads since they share the same memory space so if you're fetching from many different areas and combining the data, threading is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-carpet",
   "metadata": {},
   "source": [
    "# When should we not use threading?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-sucking",
   "metadata": {},
   "source": [
    "1. There is overhead associated with managing threads\n",
    "2. Increases the complexity of the program, which can make debugging more difficult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-spare",
   "metadata": {},
   "source": [
    "# An example of multithreading using ThreadPool.Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-mainstream",
   "metadata": {},
   "source": [
    "- example of multithreading\n",
    "    - enrichdata without threading, with threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-henry",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-silver",
   "metadata": {},
   "source": [
    "- [https://blog.floydhub.com/multiprocessing-vs-threading-in-python-what-every-data-scientist-needs-to-know/](https://blog.floydhub.com/multiprocessing-vs-threading-in-python-what-every-data-scientist-needs-to-know/)\n",
    "- [https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/](https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/)\n",
    "- [https://www.educative.io/edpresso/what-is-multithreading-in-python](https://www.educative.io/edpresso/what-is-multithreading-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-apparatus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
